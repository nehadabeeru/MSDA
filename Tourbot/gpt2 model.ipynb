{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4186845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndabe\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    What is the top rated Parks in Santa Barbara? ...\n",
      "1    What is the top rated Restaurant in Santa Barb...\n",
      "2    What is the top rated Home Services in Santa B...\n",
      "3    What is the top rated Shopping in Santa Barbar...\n",
      "4    What is the top rated Tourism in Santa Barbara...\n",
      "Name: text, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndabe\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "# Load data\n",
    "with open('questions_answers.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Combine question and answer into a single text entry\n",
    "df['text'] = df['question'] + \" Answer: \" + df['answer']\n",
    "\n",
    "# Display first few entries\n",
    "print(df['text'].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac48d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the data\n",
    "encodings = tokenizer(df['text'].tolist(), truncation=True, padding=\"max_length\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f06f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class YelpDataset(Dataset):\n",
    "    \"\"\"Dataset class for Yelp data.\"\"\"\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves an item by index and converts it to a PyTorch tensor.\n",
    "        # This method needs to return a dictionary with the input_ids and attention_mask.\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset.\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf712998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Example DataFrame and tokenizer setup\n",
    "# df = pd.DataFrame({'text': [\"example text 1\", \"example text 2\", \"example text 3\"]})\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # if your model requires pad token\n",
    "\n",
    "# Splitting the data\n",
    "train_df, val_df = train_test_split(df, test_size=0.1)  # Split data into 90% training and 10% validation\n",
    "\n",
    "# Tokenize both datasets\n",
    "train_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=\"max_length\", max_length=512)\n",
    "val_encodings = tokenizer(val_df['text'].tolist(), truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# Create datasets using the YelpDataset class\n",
    "train_dataset = YelpDataset(train_encodings)\n",
    "val_dataset = YelpDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfdb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = item['input_ids'].clone()  # Set labels to be the same as input_ids\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "dataset = YelpDataset(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085c33fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32636\\251569233.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Initialize the Trainer with both training and validation datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m trainer = Trainer(\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Initialize training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"steps\"\n",
    ")\n",
    "\n",
    "# Initialize the Trainer with both training and validation datasets\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset  # Include the validation dataset here\n",
    ")\n",
    "\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc30a525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13626962900161743, 'eval_runtime': 13.1056, 'eval_samples_per_second': 0.992, 'eval_steps_per_second': 0.153, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = trainer.evaluate()\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c14424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'What is the top rated Education in Santa Barbara? Answer: Santa Barbara School of Art is located at 805 Folsom St, rated 5.0 stars'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "test_question = \"What is the top rated Education in Santa Barbara?\"\n",
    "generated_answer = generator(test_question, max_length=100, num_return_sequences=1)\n",
    "print(generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ff52e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained('./model')\n",
    "tokenizer.save_pretrained('./model')\n",
    "\n",
    "# To load them back:\n",
    "model = GPT2LMHeadModel.from_pretrained('./model')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96481467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: transformers in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (4.34.1)\n",
      "Requirement already satisfied: click in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ndabe\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69aa136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndabe\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the top rated Restaurant in Santa Barbara?\n",
      "Answer: What is the top rated Restaurant in Santa Barbara? Answer: Katsu Coffee Bar\n",
      "\n",
      "Question: What is the top rated Park?\n",
      "Answer: What is the top rated Park? Answer: Park at Lakeview Mall located at 875 W 5th St, rated 5.0 stars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load your trained model and tokenizer\n",
    "model_path = './model'  # Corrected model path to the directory where you saved your model and tokenizer\n",
    "generator = pipeline('text-generation', model=model_path)\n",
    "\n",
    "# Generate text\n",
    "test_questions = [\"What is the top rated Restaurant in Santa Barbara?\", \"What is the top rated Park?\"]\n",
    "predictions = [generator(question, max_length=50, num_return_sequences=1)[0]['generated_text'] for question in test_questions]\n",
    "\n",
    "# Optionally, print the predictions to see the output\n",
    "for question, prediction in zip(test_questions, predictions):\n",
    "    print(f\"Question: {question}\\nAnswer: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5765cccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the top rated Parks in Santa Barbara?\n",
      "Answer: What is the top rated Parks in Santa Barbara? Answer: Park at Santa Barbara Recreation Center located at 2030 East 57th St, rated 5.0 stars\n",
      "\n",
      "Question: What is the top rated Tourism in Santa Barbara?\n",
      "Answer: What is the top rated Tourism in Santa Barbara? Answer: Santa Barbara is located at 504 Fauntleroy Canyon Blvd, rated 5.0 stars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load your trained model and tokenizer\n",
    "model_path = './model'  # Corrected model path to the directory where you saved your model and tokenizer\n",
    "generator = pipeline('text-generation', model=model_path)\n",
    "\n",
    "# Generate text\n",
    "test_questions = [\"What is the top rated Parks in Santa Barbara?\", \"What is the top rated Tourism in Santa Barbara?\"]\n",
    "predictions = [generator(question, max_length=50, num_return_sequences=1)[0]['generated_text'] for question in test_questions]\n",
    "\n",
    "# Optionally, print the predictions to see the output\n",
    "for question, prediction in zip(test_questions, predictions):\n",
    "    print(f\"Question: {question}\\nAnswer: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62ceb47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.14596369930128356\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Assuming actual_answers is a list of strings containing the correct answers\n",
    "actual_answers = [\"Alameda Park located at 1400 Santa Barbara St, rated 5.0 stars\", \"FreeWalkingTourSB located at Santa Barbara, CA, 93101, rated 5.0 stars\"]  # Update this list with actual data\n",
    "\n",
    "# Calculate BLEU Score\n",
    "bleu_scores = [sentence_bleu([word_tokenize(ref)], word_tokenize(pred)) for ref, pred in zip(actual_answers, predictions)]\n",
    "average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "print(\"Average BLEU Score:\", average_bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fac4124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the top rated Hospital in Carpinteria?\n",
      "Answer: What is the top rated Hospital in Carpinteria? Answer: Kaitlin Hospital located at Carpinteria, IL, 84138, rated 5.0 stars\n",
      "\n",
      "Question: What is the top rated Pub in Carpinteria?\n",
      "Answer: What is the top rated Pub in Carpinteria? Answer: Kitten Ranch located at 3125 El Plante St, rated 5.0 stars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load your trained model and tokenizer\n",
    "model_path = './model'  # Corrected model path to the directory where you saved your model and tokenizer\n",
    "generator = pipeline('text-generation', model=model_path)\n",
    "\n",
    "# Generate text\n",
    "test_questions = [\"What is the top rated Hospital in Carpinteria?\", \"What is the top rated Pub in Carpinteria?\"]\n",
    "predictions = [generator(question, max_length=50, num_return_sequences=1)[0]['generated_text'] for question in test_questions]\n",
    "\n",
    "# Optionally, print the predictions to see the output\n",
    "for question, prediction in zip(test_questions, predictions):\n",
    "    print(f\"Question: {question}\\nAnswer: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20ea58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the top rated Automotive in Santa Barbara?\n",
      "Answer: What is the top rated Automotive in Santa Barbara? Answer: Kattie's Auto Repair located at 900-675 N. Mission St, rated 5.0 stars\n",
      "\n",
      "Question: What is the top rated Florist Services in Santa Barbara?\n",
      "Answer: What is the top rated Florist Services in Santa Barbara? Answer: Drinks and Baking, Deli, Baristas and Hotels here at Santa Barbara have been located in the Mission Hills. We offer one of the best prices anywhere in Santa\n",
      "\n",
      "Question: What is the top rated Antique in Santa Barbara?\n",
      "Answer: What is the top rated Antique in Santa Barbara? Answer: Santa Barbara Antiques located at 5036 N Santa Monica Drive, rated 5.0 stars\n",
      "\n",
      "Question: What is the top rated Parks in Goleta?\n",
      "Answer: What is the top rated Parks in Goleta? Answer: Sandbattles National Park in Goleta, CA, 5.0 stars\n",
      "\n",
      "Question: What is the top rated Home Services in Goleta?\n",
      "Answer: What is the top rated Home Services in Goleta? Answer: The First Home Services located at 1860 S. S. Highway, rated 5.0 stars by 15 reviewers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load your trained model and tokenizer\n",
    "model_path = './model'  # Corrected model path to the directory where you saved your model and tokenizer\n",
    "generator = pipeline('text-generation', model=model_path)\n",
    "\n",
    "# Generate text\n",
    "test_questions = [\"What is the top rated Automotive in Santa Barbara?\", \"What is the top rated Florist Services in Santa Barbara?\", \"What is the top rated Antique in Santa Barbara?\", \"What is the top rated Parks in Goleta?\", \"What is the top rated Home Services in Goleta?\"]\n",
    "predictions = [generator(question, max_length=50, num_return_sequences=1)[0]['generated_text'] for question in test_questions]\n",
    "\n",
    "# Optionally, print the predictions to see the output\n",
    "for question, prediction in zip(test_questions, predictions):\n",
    "    print(f\"Question: {question}\\nAnswer: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d508881a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.07007135413545701\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Assuming actual_answers is a list of strings containing the correct answers\n",
    "actual_answers = [\"Oren's Automotive located at 227 Gray Ave, rated 5.0 stars\", \"ella & louie flowers located at Santa Barbara, CA, 93101, rated 5.0 stars\", \"Santa Barbara Baby Company located at Santa Barbara, CA, 93108, rated 5.0 stars\", \"Evergreen Open Space Disc Golf Course located at Evergreen Drive And Brandon Dr, rated 5.0 stars\", \"Carpeteria Carpet One Floor & Home Santa Barbara located at 5610 Hollister Ave, rated 5.0 stars\"]\n",
    "\n",
    "# Calculate BLEU Score\n",
    "bleu_scores = [sentence_bleu([word_tokenize(ref)], word_tokenize(pred)) for ref, pred in zip(actual_answers, predictions)]\n",
    "average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "print(\"Average BLEU Score:\", average_bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae5e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
